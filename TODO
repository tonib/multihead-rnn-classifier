TODO:
- Add option to use XLA
- ClassifierHead > tf_feature_column.embedding_column(), parm trainable should be false in inference time?
- Check how VS code can find TF definitions
- Check how VS code can use the venv
- Install and use a linter
- Add documentation about embedding
- Each column should have it's own padding value
- Inference time: Support padding automatically
- Remove warning messages...
- Option to fix the seed to make model comparisons (https://stackoverflow.com/questions/51072735/using-tf-set-random-seed-with-tf-estimator-estimator)
- Use tfrecord files? (https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564)
- More on performance:
  https://stackoverflow.com/questions/47086599/parallelising-tf-data-dataset-from-generator
  https://stackoverflow.com/questions/48484689/parallelism-isnt-reducing-the-time-in-dataset-map/48781036#48781036
- Allow to configure the padding value for each column?
- Model server: Autopad sequences
- Generate a file with the last evaluation info: It will be used to ponderate probabilites based on accuracy
- Allow to configure weight decay?
- DOCUMENTATION: Add prerequisites (tf, pandas,...)
- Configure MKL ???
- Slow performance in Windows with custom estimator (dropout?)

REMINDERS

git push -u origin master

tensorboard --logdir data/model
http://localhost:6006

Estimator inference performance / Serving model / Use of Predictor:
https://github.com/MtDersvan/tf_playground/blob/master/wide_and_deep_tutorial/wide_and_deep_basic_serving.md
https://github.com/tensorflow/tensorflow/issues/4648
https://gist.github.com/mikeoconnor0308/521ae2eb1555edc6550014ce0500e6a2
https://cs230-stanford.github.io/tensorflow-input-data.html#introduction-to-tfdata-with-a-text-example
https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/

Export model and predict / serve:
    http://shzhangji.com/blog/2018/05/14/serve-tensorflow-estimator-with-savedmodel/


* saved_model_cli:
    # Show prediction function signature for canned estimator
    saved_model_cli show --dir=data/exportedmodels/1564680586 --tag_set serve --signature_def predict
    # Show prediction function signature for custom estimator
    saved_model_cli show --dir=data/exportedmodels/1564760074 --tag_set serve --signature_def serving_default

tensorflow_model_server --port=9000 --model_base_path=exportedmodel/1545244360

START WITH THIS:
https://stackoverflow.com/questions/46098863/how-to-import-an-saved-tensorflow-model-train-using-tf-estimator-and-predict-on/46139198

222 CPM -> 48 WPM
3,7 CPS -> 0,8 WPS

requirements:
Visual C++ 2015 Redistributable (Windows)
CPU may requiere AVX (see https://github.com/tensorflow/tensorflow/issues/17386)
pyton 3.6.7
tensorflow 1.14
numpy 1.16.1
pandas 0.24.2 # pip install pandas

* Install Tensorflow in Windows with virtualenv
** Install Python 3.6.7
	- Download Python 3.6.7 ("Windows x86-64 executable installer" link) from https://www.python.org/downloads/release/python-367/ 
	  (or at LSI get it at H:\Programacion\Python)
	- Run setup
	- Mark "Add Python 3.6 to PATH"
	- Click "install now"

** Install tensorflow 1.14 Windows with virtualenv
    cd [PARENT_DIR]

	REM Install virtualenv
	pip install virtualenv

	REM Create the virtualenv
    virtualenv --system-site-packages -p python ./venv

	REM Activate the virtualenv
    .\venv\Scripts\activate

	REM Upgrade pip?
    pip install --upgrade pip

	REM Why?
    REM pip list

    REM Only for TF 1.14. It show warnings if numpy=1.17.0 is installed
    pip install numpy==1.16.4

	REM Install tensorflow 1.14
    REM pip install --upgrade tensorflow < NOT TO THE LATEST VERSION!
	pip install tensorflow==1.14

	REM Test tf installation
    python -c "import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))"

    REM Install pandas
    pip install pandas==0.24.2

* Install Tensorflow 1.14 in Linux with virtualenv
    # This is required for me in Ubuntu 20 (https://stackoverflow.com/questions/61541281/python-3-7-venv-broken-after-upgrade-to-ubuntu-20-04)
    # sudo add-apt-repository ppa:deadsnakes/ppa
    # sudo apt-get update
    # sudo apt-get install python3.7
    # sudo apt-get install python3.7-venv

    # In Ubuntu 20 use: virtualenv --python=/usr/bin/python3.7 ./venv
    virtualenv --system-site-packages -p python3 ./venv

    source ./venv/bin/activate
    pip install --upgrade pip
    pip list
    # Only for TF 1.14. It show warnings if numpy=1.17.0 is installed
    pip install numpy==1.16.4
    #pip install --upgrade tensorflow NOT TO THE LATEST VERSION
    pip install tensorflow==1.14
    # Test TF installation
    python -c "import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))"
    pip install pandas==0.24.2

* Install TF 1.14 with GPU support in Ubuntu 20.04 with venv

    # Install TF, and pandas
    sudo apt install python3-dev python3-pip python3-venv
    python3 -m venv --system-site-packages ./venv
    source ./venv/bin/activate
    pip install --upgrade pip
    pip list
    # Only for TF 1.14. It show warnings if numpy=1.17.0 is installed
    pip install numpy==1.16.4
    pip install tensorflow-gpu==1.14
    pip install pandas==0.24.2

    # Add NVIDIA package repositories. This is the repository for Ubuntu 18.04, but it works for 20.04 (repo for 20.04 contains only
    # CUDA v11)
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.243-1_amd64.deb
    sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
    sudo dpkg -i cuda-repo-ubuntu1804_10.1.243-1_amd64.deb
    sudo apt-get update
    wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt-get update

    # Install NVIDIA driver
    # I KEPT nvidia-driver-440 and it worked
    # sudo apt-get install --no-install-recommends nvidia-driver-450
    # Reboot. Check that GPUs are visible using the command: nvidia-smi

    # Install development and runtime libraries (CUDA 10.0)
    sudo apt-get install -y --no-install-recommends \
    cuda-10-0 \
    libcudnn7=7.6.4.38-1+cuda10.0  \
    libcudnn7-dev=7.6.4.38-1+cuda10.0;

    sudo apt-get install -y --no-install-recommends \
        libnvinfer6=6.0.1-1+cuda10.0 \
        libnvinfer-dev=6.0.1-1+cuda10.0 \
        libnvinfer-plugin6=6.0.1-1+cuda10.0;

* Prediction format:
Prediction: {'isCollection': {'class_prediction': 0, 'probabilities': [0.9971703886985779, 0.0028295705560594797]}, 'legthBucket': {'class_prediction': 0, 'probabilities': [0.38102802634239197, 0.3096150755882263, 0.013816392980515957, 0.1163591593503952, 0.006184279453009367, 0.0024974108673632145, 0.0019232947379350662, 0.01665205880999565, 0.005016367882490158, 0.0043900893069803715, 0.0362323597073555, 0.004558942746371031, 0.0015884715830907226, 0.029023174196481705, 0.014890970662236214, 0.04388183727860451, 0.008182627148926258, 0.004159428644925356]}, 'decimalsBucket': {'class_prediction': 0, 'probabilities': [0.9940299987792969, 3.4467918794689467e-06, 0.0036471218336373568, 0.0001381940091960132, 5.111771770316409e-0

* Metrics format:
{'accuracy/decimalsBucket': 0.9587786, 'accuracy/isCollection': 0.9969466, 'accuracy/legthBucket': 0.66431296, 'accuracy/outputTypeIdx': 0.64122134, 'accuracy_baseline/isCollection': 0.9969466, 'auc/isCollection': 0.9759284, 'auc_precision_recall/isCollection': 0.08735464, 'average_loss/decimalsBucket': 0.16012691, 'average_loss/isCollection': 0.0133258775, 'average_loss/legthBucket': 1.2138829, 'average_loss/outputTypeIdx': 1.2020633, 'label/mean/isCollection': 0.0030534351, 'loss': 165.4689, 'loss/decimalsBucket': 10.2325, 'loss/isCollection': 0.85155606, 'loss/legthBucket': 77.57008, 'loss/outputTypeIdx': 76.81478, 'precision/isCollection': 0.0, 'prediction/mean/isCollection': 0.0034022834, 'recall/isCollection': 0.0, 'global_step': 3108}

***** CUSTOM ESTIMATOR, WITH EMBEDDING DIM. 10, AFTER 14 EPOCHS:

Training epoch 7 ...
2020-07-26 14:01:11.847154: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 4921 of 5000
2020-07-26 14:01:11.984224: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.9193122, 'accuracy/isCollection': 0.92724866, 'accuracy/isControl': 0.8452381, 'accuracy/lengthBucket': 0.7255291, 'accuracy/outputTypeIdx': 0.45304233, 'accuracy/textHash0': 0.5734127, 'accuracy/textHash1': 0.5839947, 'accuracy/textHash2': 0.8095238, 'accuracy/textHash3': 0.8955026, 'loss': 0.926258, 'loss/decimalsBucket': 0.26557323, 'loss/isCollection': 0.20280845, 'loss/isControl': 0.4019108, 'loss/lengthBucket': 1.0370004, 'loss/outputTypeIdx': 2.193466, 'loss/textHash0': 1.463703, 'loss/textHash1': 1.4772863, 'loss/textHash2': 0.88384956, 'loss/textHash3': 0.41072297, 'global_step': 2583}
Evaluation time: 6.750043153762817 s
Loss decrease: 3.671252354979515 %
Epoch time: 64.20589995384216 s
Train speed:  827.1796161216843 sequences / s
Total train time: 454.7265121936798 s
Prediction performance: 3.5602307319641113 ms

***** CUSTOM ESTIMATOR, WITH NO EMBEDDING

Training epoch 7 ...
2020-07-26 13:49:01.218848: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 4770 of 5000
2020-07-26 13:49:01.623044: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.9232804, 'accuracy/isCollection': 0.92724866, 'accuracy/isControl': 0.8234127, 'accuracy/lengthBucket': 0.7248677, 'accuracy/outputTypeIdx': 0.48280424, 'accuracy/textHash0': 0.58267194, 'accuracy/textHash1': 0.5906085, 'accuracy/textHash2': 0.80224866, 'accuracy/textHash3': 0.8935185, 'loss': 0.9449695, 'loss/decimalsBucket': 0.2846151, 'loss/isCollection': 0.21228914, 'loss/isControl': 0.41285062, 'loss/lengthBucket': 1.0846995, 'loss/outputTypeIdx': 2.1391752, 'loss/textHash0': 1.5357685, 'loss/textHash1': 1.5327793, 'loss/textHash2': 0.8813905, 'loss/textHash3': 0.4211564, 'global_step': 2583}
Evaluation time: 4.95462703704834 s
Loss decrease: 2.922206185758114 %
Epoch time: 57.187389612197876 s
Train speed:  909.8939413408656 sequences / s
Total train time: 387.0955402851105 s

***** CANNED ESTIMATOR RESULTS:

Training epoch 7 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.8922086, 'accuracy/isCollection': 0.90743995, 'accuracy/isControl': 0.8172232, 'accuracy/lengthBucket': 0.75454015, 'accuracy/outputTypeIdx': 0.62038666, 'accuracy/textHash0': 0.56004685, 'accuracy/textHash1': 0.50087875, 'accuracy/textHash2': 0.64674866, 'accuracy/textHash3': 0.8471002, 'average_loss/decimalsBucket': 0.34259295, 'average_loss/isCollection': 0.26767275, 'average_loss/isControl': 0.44271556, 'average_loss/lengthBucket': 0.92358184, 'average_loss/outputTypeIdx': 1.3751706, 'average_loss/textHash0': 1.5086322, 'average_loss/textHash1': 1.7459004, 'average_loss/textHash2': 1.4039731, 'average_loss/textHash3': 0.58956563, 'loss': 543.6987, 'loss/decimalsBucket': 21.659487, 'loss/isCollection': 16.922865, 'loss/isControl': 27.989462, 'loss/lengthBucket': 58.390896, 'loss/outputTypeIdx': 86.941345, 'loss/textHash0': 95.37908, 'loss/textHash1': 110.3797, 'loss/textHash2': 88.7623, 'loss/textHash3': 37.27365, 'global_step': 2562}
Loss decrease: 2.837500162422657 %
Epoch time: 60.147926807403564 s
Train speed:  893.4642030883039 sequences / s
Total train time: 416.1845705509186 s


***** CUSTOM ESTIMATOR RESULTS (WITH ADAM LR=0.001):

Training epoch 7 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.90978324, 'accuracy/isCollection': 0.923843, 'accuracy/isControl': 0.82132393, 'accuracy/lengthBucket': 0.7680141, 'accuracy/outputTypeIdx': 0.6385472, 'accuracy/textHash0': 0.55008787, 'accuracy/textHash1': 0.52899826, 'accuracy/textHash2': 0.65319276, 'accuracy/textHash3': 0.84827185, 'loss': 0.9055806, 'loss/decimalsBucket': 0.27407032, 'loss/isCollection': 0.1940389, 'loss/isControl': 0.40906608, 'loss/lengthBucket': 0.840173, 'loss/outputTypeIdx': 1.2997233, 'loss/textHash0': 1.5318633, 'loss/textHash1': 1.6802183, 'loss/textHash2': 1.3469537, 'loss/textHash3': 0.5741187, 'global_step': 2562}
Loss decrease: 1.9855810329318047 %
Epoch time: 60.139899015426636 s
Train speed:  884.0166602083842 sequences / s
Total train time: 417.6330919265747 s

***** CUSTOM ESTIMATOR RESULTS (WITH ADAGRAD LR=0.001):

Training epoch 7 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.82542473, 'accuracy/isCollection': 0.7797305, 'accuracy/isControl': 0.6403046, 'accuracy/lengthBucket': 0.46104276, 'accuracy/outputTypeIdx': 0.27475104, 'accuracy/textHash0': 0.36965436, 'accuracy/textHash1': 0.36965436, 'accuracy/textHash2': 0.35969537, 'accuracy/textHash3': 0.6672525, 'loss': 1.7938948, 'loss/decimalsBucket': 0.81162935, 'loss/isCollection': 0.6265011, 'loss/isControl': 0.9564013, 'loss/lengthBucket': 2.101575, 'loss/outputTypeIdx': 4.129237, 'loss/textHash0': 2.3231707, 'loss/textHash1': 2.322795, 'loss/textHash2': 1.9142047, 'loss/textHash3': 0.95953906, 'global_step': 2562}
Loss decrease: 2.2231029346585274 %
Epoch time: 59.60072875022888 s
Train speed:  888.1659150241711 sequences / s
Total train time: 417.63799262046814 s

***** CUSTOM ESTIMATOR RESULTS (WITH ADAGRAD LR=0.01):

Training epoch 7 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.8523726, 'accuracy/isCollection': 0.87697715, 'accuracy/isControl': 0.7510252, 'accuracy/lengthBucket': 0.53192735, 'accuracy/outputTypeIdx': 0.3274751, 'accuracy/textHash0': 0.45635617, 'accuracy/textHash1': 0.44229642, 'accuracy/textHash2': 0.589338, 'accuracy/textHash3': 0.7627416, 'loss': 1.365712, 'loss/decimalsBucket': 0.47252694, 'loss/isCollection': 0.33154684, 'loss/isControl': 0.5855228, 'loss/lengthBucket': 1.6641496, 'loss/outputTypeIdx': 2.766147, 'loss/textHash0': 2.0324504, 'loss/textHash1': 2.069033, 'loss/textHash2': 1.6362826, 'loss/textHash3': 0.73375016, 'global_step': 2562}
Loss decrease: 4.390760511159897 %
Epoch time: 61.27667689323425 s
Train speed:  859.2366112232901 sequences / s
Total train time: 432.45619797706604 s

***** CUSTOM ESTIMATOR RESULTS (WITH ADADELTA LR=0.001):

Training epoch 7 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.0, 'accuracy/isCollection': 0.27006444, 'accuracy/isControl': 0.60046864, 'accuracy/lengthBucket': 0.005858231, 'accuracy/outputTypeIdx': 0.0029291154, 'accuracy/textHash0': 0.06033978, 'accuracy/textHash1': 0.025190393, 'accuracy/textHash2': 0.010544815, 'accuracy/textHash3': 0.33391917, 'loss': 2.682517, 'loss/decimalsBucket': 2.5561109, 'loss/isCollection': 1.1220706, 'loss/isControl': 1.0317847, 'loss/lengthBucket': 3.2260268, 'loss/outputTypeIdx': 5.0380974, 'loss/textHash0': 2.796789, 'loss/textHash1': 2.9921355, 'loss/textHash2': 2.8411822, 'loss/textHash3': 2.5384595, 'global_step': 2562}
Loss decrease: 0.37268733140081167 %
Epoch time: 59.67932605743408 s
Train speed:  885.4324346721702 sequences / s
Total train time: 414.78500533103943 s

***** CANNED ESTIMATOR RESULTS (WITH ADADELTA LR=0.001):
Does not converge in 7 epochs...


***** CANNED WITHOUT REGULARIZATION:
2 X 14 epochs

Training epoch 14 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.9452355, 'accuracy/isCollection': 0.9611172, 'accuracy/isControl': 0.8926616, 'accuracy/lengthBucket': 0.80394304, 'accuracy/outputTypeIdx': 0.67360353, 'accuracy/textHash0': 0.63910186, 'accuracy/textHash1': 0.6516977, 'accuracy/textHash2': 0.7968237, 'accuracy/textHash3': 0.91675794, 'loss': 0.7449024, 'loss/decimalsBucket': 0.22228292, 'loss/isCollection': 0.16516204, 'loss/isControl': 0.34762415, 'loss/lengthBucket': 0.7754909, 'loss/outputTypeIdx': 1.1429765, 'loss/textHash0': 1.387189, 'loss/textHash1': 1.3443204, 'loss/textHash2': 0.9116318, 'loss/textHash3': 0.40744302, 'global_step': 10192}
Loss decrease: -0.06194728775881231 %
Epoch time: 56.27888107299805 s
Train speed:  938.3999039017369 sequences / s
Total train time: 781.4033198356628 s

***** CANNED WITH DROPOUT=0.2:

Training epoch 28 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.95071197, 'accuracy/isCollection': 0.96385545, 'accuracy/isControl': 0.8921139, 'accuracy/lengthBucket': 0.8066813, 'accuracy/outputTypeIdx': 0.6719606, 'accuracy/textHash0': 0.6385542, 'accuracy/textHash1': 0.6555312, 'accuracy/textHash2': 0.79299015, 'accuracy/textHash3': 0.9118291, 'loss': 0.763899, 'loss/decimalsBucket': 0.22207701, 'loss/isCollection': 0.16671908, 'loss/isControl': 0.36492106, 'loss/lengthBucket': 0.8005293, 'loss/outputTypeIdx': 1.2252389, 'loss/textHash0': 1.3597565, 'loss/textHash1': 1.3479313, 'loss/textHash2': 0.93950206, 'loss/textHash3': 0.4484174, 'global_step': 10192}
Loss decrease: -2.657121606171131 %
Epoch time: 53.85472869873047 s
Train speed:  978.4682507230793 sequences / s
Total train time: 1511.6734700202942 s

Training epoch 42 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.9501643, 'accuracy/isCollection': 0.9600219, 'accuracy/isControl': 0.8959474, 'accuracy/lengthBucket': 0.80996716, 'accuracy/outputTypeIdx': 0.67688936, 'accuracy/textHash0': 0.64348304, 'accuracy/textHash1': 0.6686747, 'accuracy/textHash2': 0.7935378, 'accuracy/textHash3': 0.9140197, 'loss': 0.8200377, 'loss/decimalsBucket': 0.2757146, 'loss/isCollection': 0.21188809, 'loss/isControl': 0.39395055, 'loss/lengthBucket': 0.88494647, 'loss/outputTypeIdx': 1.3175423, 'loss/textHash0': 1.4297101, 'loss/textHash1': 1.3801568, 'loss/textHash2': 1.0037055, 'loss/textHash3': 0.4827256, 'global_step': 15288}
Loss decrease: -0.675475038588047 %
Epoch time: 53.78201389312744 s
Train speed:  978.7492047605747 sequences / s
Total train time: 2265.917642593384 s

***** LSTM
Training epoch 7 ...
Evaluating...
Evaluation:  {'accuracy/decimalsBucket': 0.8958223, 'accuracy/isCollection': 0.90111053, 'accuracy/isControl': 0.78688526, 'accuracy/lengthBucket': 0.7503966, 'accuracy/outputTypeIdx': 0.46589106, 'accuracy/textHash0': 0.47435218, 'accuracy/textHash1': 0.5156002, 'accuracy/textHash2': 0.69804335, 'accuracy/textHash3': 0.8291909, 'loss': 1.2573891, 'loss/decimalsBucket': 0.48740742, 'loss/isCollection': 0.38421234, 'loss/isControl': 0.7827207, 'loss/lengthBucket': 1.2866995, 'loss/outputTypeIdx': 2.2613883, 'loss/textHash0': 1.9677442, 'loss/textHash1': 2.0415328, 'loss/textHash2': 1.4332529, 'loss/textHash3': 0.67154276, 'global_step': 2541}
Loss decrease: -10.175096988677979 %
Epoch time: 55.70764088630676 s
Train speed:  946.3386247127988 sequences / s
Total train time: 397.102126121521 s

